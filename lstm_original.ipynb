{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_original.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA_fJ7uL1t4u"
      },
      "source": [
        "Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cmv_LIq09Cw"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import time\n",
        "import keras.backend as K\n",
        "import math\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, LSTM, Bidirectional, Dropout, TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import auc, roc_curve, auc, mean_squared_error, mean_absolute_error\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import concatenate\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "# import tf.keras.preprocessing.timeseries_dataset_from_array"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCVaCO3Y1xAq"
      },
      "source": [
        "Paths y lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_UgA3opO0D"
      },
      "source": [
        "full_data_path = \"/content/drive/MyDrive/datos_web/otros/test3.csv\"\n",
        "ordered_data_path = \"/content/drive/MyDrive/datos_web/otros/cleaned_ordered.csv\"\n",
        "# ordered_data_path = \"/content/drive/MyDrive/datos_web/otros/cleaned_ordered_2.csv\"\n",
        "final_data_path = \"/content/drive/MyDrive/datos_web/otros/final_data.csv\"\n",
        "\n",
        "# test_cleaned_full_path = \"/content/drive/MyDrive/datos_web/otros/full_cleaned.csv\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWUGIlifC0wX"
      },
      "source": [
        "final_data = pd.read_csv(final_data_path)\n",
        "dates = pd.to_datetime(final_data[\"Unnamed: 0\"].values)\n",
        "final_data.drop(\"Unnamed: 0\", axis = 1, inplace=True)\n",
        "final_data.set_index(dates, inplace=True)\n",
        "\n",
        "# final_data.set_\n",
        "ordered_data = pd.read_csv(ordered_data_path)\n",
        "ordered_data.drop(\"Unnamed: 0\", axis = 1, inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JUDPOO3162w"
      },
      "source": [
        "Variables y grupos. Seleccionar datos del conjunto. Sirve para análisis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulntu8N8DAcd"
      },
      "source": [
        "barrios = {}\n",
        "tipos = {}\n",
        "carriles = {}\n",
        "entradas = {\n",
        "    \"serreria\" : [\"A233\", \"A415\", \"A235\"],\n",
        "    \"avcid\" : [\"A143\", \"A170\", \"A71\", \"A72\"],\n",
        "    \"blasco\" : [\"A49\", \"A65\", \"A33\", \"A47\"]\n",
        "}\n",
        "\n",
        "print(entradas)\n",
        "salidas = {\n",
        "    \"serreria\" : [\"A74\", \"A5\", \"A51\"],\n",
        "    \"avcid\" : [\"A72\", \"A245\"],\n",
        "    \"blasco\" : [\"A234\", \"A52\"]\n",
        "}\n",
        "print(salidas)\n",
        "\n",
        "avcid = [\"A145\", \"A70\", \"A71\", \"A72\", \"A69\"]\n",
        "# alameda = [\"A174\", \"A345\" ,\"A266\", \"A277\", \"A166\", \"A173\"]\n",
        "alameda = [\"A174\", \"A345\" ,\"A173\"]\n",
        "# genaro = [\"B24\", \"B118\", \"B81\"]\n",
        "genaro = [\"B24\", \"B81\", \"B118\", \"B57\"]\n",
        "# avmed = [\"A131\", \"A179\", \"A104\", \"A88\", \"A351\" ]\n",
        "avmed = [\"A131\", \"A179\", \"A351\" ]\n",
        "# justopastor = [\"A415\", \"A359\", \"A92\", \"A230\",\"A231\"]\n",
        "justopastor = [\"A415\", \"A359\", \"A92\", \"A231\"]\n",
        "# baron = [\"A98\", \"B29\", \"B10\"]\n",
        "baron = [\"A98\", \"B10\"]\n",
        "# Barrios\n",
        "grouped = ordered_data.groupby(ordered_data.barrio)\n",
        "for name, group in grouped:\n",
        "  neighs = list(set(group.ATA))\n",
        "  barrios[name] = neighs\n",
        "print(barrios)\n",
        "\n",
        "# Tipos de calle\n",
        "grouped = ordered_data.groupby(ordered_data.tipo)\n",
        "for name, group in grouped:\n",
        "  types = list(set(group.ATA))\n",
        "  tipos[name] = types\n",
        "print(tipos)\n",
        "\n",
        "# Mismos carriles\n",
        "grouped = ordered_data.groupby(ordered_data.carriles)\n",
        "for name, group in grouped:\n",
        "  lanes = list(set(group.ATA))\n",
        "  carriles[name] = lanes\n",
        "print(carriles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bshFEeA8S7n_"
      },
      "source": [
        "barrio = barrios['algiros']\n",
        "\n",
        "datos = final_data[barrio]\n",
        "# datos = datos.iloc[datos.index.dayofweek == 0]\n",
        "# Para entrenar modelo final\n",
        "train = datos[\"2021-03-15 00:00:00\":\"2021-06-06 23:00:00\"]\n",
        "# test = datos[\"2021-06-07 00:00:00\":\"2021-06-20 23:00:00\"]\n",
        "\n",
        "# train = datos[\"2021-03-15 00:00:00\":\"2021-05-16 23:00:00\"]\n",
        "# val = datos[\"2021-05-17 00:00:00\":\"2021-06-06 23:00:00\"]\n",
        "test = datos[\"2021-06-07 00:00:00\":\"2021-06-20 23:00:00\"]\n",
        "\n",
        "\n",
        "mondays_train = train.iloc[train.index.dayofweek == 0]\n",
        "tuesdays_train = train.iloc[train.index.dayofweek == 1]\n",
        "wednesdays_train = train.iloc[train.index.dayofweek == 2]\n",
        "thursdays_train = train.iloc[train.index.dayofweek == 3]\n",
        "fridays_train = train.iloc[train.index.dayofweek == 4]\n",
        "saturdays_train = train.iloc[train.index.dayofweek == 5]\n",
        "sundays_train = train.iloc[train.index.dayofweek == 6]\n",
        "\n",
        "mondays_test = test.iloc[test.index.dayofweek == 0]\n",
        "tuesdays_test = test.iloc[test.index.dayofweek == 1]\n",
        "wednesdays_test = test.iloc[test.index.dayofweek == 2]\n",
        "thursdays_test = test.iloc[test.index.dayofweek == 3]\n",
        "fridays_test = test.iloc[test.index.dayofweek == 4]\n",
        "saturdays_test = test.iloc[test.index.dayofweek == 5]\n",
        "sundays_test = test.iloc[test.index.dayofweek == 6]\n",
        "\n",
        "features = datos.shape[1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEtX_OdPlZij"
      },
      "source": [
        "barr = list(set(barrios.keys()))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw2W2JYiIDxo"
      },
      "source": [
        "Para crear la serie temporal completa, esta parte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3td6WOZVDZGB"
      },
      "source": [
        "\n",
        "datos = final_data\n",
        "\n",
        "datos = datos[\"2021-03-15 00:00:00\":\"2021-06-20 23:00:00\"]\n",
        "datos_pre = datos[\"2021-03-15 00:00:00\":\"2021-05-09 23:00:00\"]\n",
        "datos_post = datos[\"2021-05-10 00:00:00\":\"2021-06-20 23:00:00\"]\n",
        "datos = datos[\"2021-03-15 00:00:00\":\"2021-06-20 23:00:00\"]\n",
        "datos.fillna(0, inplace=True)\n",
        "\n",
        "# datos = datos.iloc[datos.index.dayofweek == 0]\n",
        "# Para entrenar modelo final\n",
        "train = datos[\"2021-03-15 00:00:00\":\"2021-06-06 23:00:00\"]\n",
        "test = datos[\"2021-06-07 00:00:00\":\"2021-06-20 23:00:00\"]\n",
        "\n",
        "# train = datos[\"2021-03-15 00:00:00\":\"2021-05-16 23:00:00\"]\n",
        "val = datos[\"2021-05-17 00:00:00\":\"2021-06-06 23:00:00\"]\n",
        "# test = datos[\"2021-06-07 00:00:00\":\"2021-06-20 23:00:00\"]\n",
        "\n",
        "\n",
        "mondays_train = train.iloc[train.index.dayofweek == 0]\n",
        "tuesdays_train = train.iloc[train.index.dayofweek == 1]\n",
        "wednesdays_train = train.iloc[train.index.dayofweek == 2]\n",
        "thursdays_train = train.iloc[train.index.dayofweek == 3]\n",
        "fridays_train = train.iloc[train.index.dayofweek == 4]\n",
        "saturdays_train = train.iloc[train.index.dayofweek == 5]\n",
        "sundays_train = train.iloc[train.index.dayofweek == 6]\n",
        "weekdays_train = mondays_train.append(tuesdays_train).append(wednesdays_train).append(thursdays_train).append(fridays_train)\n",
        "weekends_train = saturdays_train.append(sundays_train)\n",
        "\n",
        "mondays_test = test.iloc[test.index.dayofweek == 0]\n",
        "tuesdays_test = test.iloc[test.index.dayofweek == 1]\n",
        "wednesdays_test = test.iloc[test.index.dayofweek == 2]\n",
        "thursdays_test = test.iloc[test.index.dayofweek == 3]\n",
        "fridays_test = test.iloc[test.index.dayofweek == 4]\n",
        "saturdays_test = test.iloc[test.index.dayofweek == 5]\n",
        "sundays_test = test.iloc[test.index.dayofweek == 6]\n",
        "weekdays_test = mondays_test.append(tuesdays_test).append(wednesdays_test).append(thursdays_test).append(fridays_test)\n",
        "weekends_test = saturdays_test.append(sundays_test)\n",
        "features = datos.shape[1]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZK0XSZD4I4S"
      },
      "source": [
        "Crear la serie temporal.\n",
        "\n",
        "2 formas diferentes :\n",
        "  1 - Método create_dataset\n",
        "  2 - Método series_to_supervised\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJyTWIGzSyrF"
      },
      "source": [
        "# # Convertir la serie temporal en datos supervisados\n",
        "# Serie sin tener en cuenta informacion adicional, solo la hora anterior\n",
        "def series_to_supervised(data, keys, n_in=1, n_out=1, dropnan=True):\n",
        "  n_vars = 1 if type(data) is list else data.shape[1]\n",
        "  df = pd.DataFrame(data)\n",
        "  cols, names = list(), list()\n",
        "  # input sequence (t-n, ... t-1)\n",
        "  for i in range(n_in, 0, -1):\n",
        "    cols.append(df.shift(i))\n",
        "    names += [('%s(t-%d)' % (keys[j], i)) for j in range(n_vars)]\n",
        "  # forecast sequence (t, t+1, ... t+n)\n",
        "  for i in range(0, n_out):\n",
        "    cols.append(df.shift(-i))\n",
        "    if i == 0:\n",
        "      names += [('%s(t)' % (keys[j])) for j in range(n_vars)]\n",
        "    else:\n",
        "      names += [('%s(t+%d)' % (keys[j], i)) for j in range(n_vars)]\n",
        "  # put it all together\n",
        "  agg = pd.concat(cols, axis=1)\n",
        "  agg.columns = names\n",
        "  # drop rows with NaN values\n",
        "  if dropnan:\n",
        "    agg.dropna(0, inplace=True)\n",
        "  return agg\n",
        "\n",
        "\n",
        "features = train.shape[1]\n",
        "timesteps = 2\n",
        "outputs = 1\n",
        "\n",
        "## Cambiar en funcion de lo que se quiera\n",
        "# train = weekdays_train\n",
        "# test = weekdays_test\n",
        "# val = weekends_val\n",
        "# train = weekends_train\n",
        "# # test = weekends_test\n",
        "\n",
        "features = train.shape[1]\n",
        "\n",
        "train_keys = train.keys()\n",
        "test_keys = test.keys()\n",
        "val_keys = val.keys()\n",
        "print(test.iloc[0:24])\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaler = scaler.fit(train)\n",
        "train_values = scaler.transform(train)\n",
        "test_values = scaler.transform(test)\n",
        "val_values = scaler.transform(val)\n",
        "\n",
        "serie_train = series_to_supervised(train_values, train_keys, n_in=1, n_out=2)\n",
        "serie_test = series_to_supervised(test_values, test_keys,  n_in=1, n_out=2)\n",
        "serie_val = series_to_supervised(val_values, val_keys, n_in=1, n_out=2)\n",
        "\n",
        "x_train, y_train = serie_train.values[:, :-features], serie_train.values[:, -features:]\n",
        "x_test, y_test = serie_test.values[:, :-features], serie_test.values[:, -features:]\n",
        "x_val, y_val = serie_val.values[:, :-features], serie_val.values[:, -features:]\n",
        "\n",
        "##############  Resize de los arrays ##########\n",
        "x_train = np.asarray(x_train).astype('float32')\n",
        "x_test = np.asarray(x_test).astype('float32')\n",
        "x_val = np.asarray(x_val).astype('float32')\n",
        "\n",
        "y_train = np.asarray(y_train).astype('float32')\n",
        "y_test = np.asarray(y_test).astype('float32')\n",
        "y_val = np.asarray(y_val).astype('float32')\n",
        "\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], timesteps, features))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], timesteps, features))\n",
        "x_val = np.reshape(x_val, (x_val.shape[0], timesteps, features))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjaK9QUn47NW"
      },
      "source": [
        "Creación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnAkeIscZiON"
      },
      "source": [
        "####### Crear y entrenar el modelo  ##########\n",
        "batch_size = 24\n",
        "epochs = 200\n",
        "# print(features, \"FEATURES\")\n",
        "# print(x_train.shape[0], \"MUESTRAS\")\n",
        "# print(timesteps, \"TIMESTEPS\")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(150, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2]), name=\"Input\"))\n",
        "model.add(Dropout(0.2, name= \"Dropout_1\"))\n",
        "model.add(Dense(units = features, name = \"Output\", activation='linear'))\n",
        "model.summary()\n",
        "metrics=[\"mse\", \"mae\"]\n",
        "model.compile(metrics=metrics, loss='mae', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS6b4bqoXu7o"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UPK6Jj4ZjTY"
      },
      "source": [
        "filepath=\"weights.best.hdf5\"\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint, es]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqcLaPLkZkQ2"
      },
      "source": [
        "# Para ajustar\n",
        "history = model.fit(\n",
        "    x_train, y_train, \n",
        "    epochs=epochs, \n",
        "    batch_size=batch_size, \n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=callbacks_list,\n",
        "    shuffle=False,\n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWYVFu_JJHxf"
      },
      "source": [
        "# Final\n",
        "history = model.fit(\n",
        "    x_train, y_train, \n",
        "    epochs=epochs, \n",
        "    batch_size=batch_size, \n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=callbacks_list,\n",
        "    shuffle=False,\n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Amyt7OZlsv"
      },
      "source": [
        "plt.title(\"MAE\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.plot(history.history['mae'], label='entrenamiento')\n",
        "plt.plot(history.history['val_mae'], label='test')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.title(\"MSE\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.plot(history.history['mse'], label='entrenamiento')\n",
        "plt.plot(history.history['val_mse'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amzSKklU13LK"
      },
      "source": [
        "val_rmse_values = []\n",
        "train_rmse_values = []\n",
        "for i in history.history['val_mse']:\n",
        "  val_rmse_values.append(math.sqrt(i))\n",
        "for i in history.history['mse']:\n",
        "  train_rmse_values.append(math.sqrt(i))\n",
        "\n",
        "\n",
        "plt.title(\"RMSE\")\n",
        "plt.plot(train_rmse_values, label='entrenamiento')\n",
        "plt.plot(val_rmse_values, label='test')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MWkBXfwU6aO"
      },
      "source": [
        "model.load_weights(\"/content/weights.best.hdf5\")\n",
        "# model.load_weights(\"/content/drive/MyDrive/datos_web/otros/weights.best.hdf5\")\n",
        "# y_test = y_train\n",
        "# # make predictions\n",
        "train_predict = model.predict(x_train)\n",
        "test_predict = model.predict(x_test)\n",
        "val_predict = model.predict(x_val)\n",
        "print(train_predict)\n",
        "train_predict_inversed = scaler.inverse_transform(train_predict)\n",
        "test_predict_inversed = scaler.inverse_transform(test_predict)  \n",
        "val_predict_inversed = scaler.inverse_transform(val_predict)  \n",
        "y_test_inversed = scaler.inverse_transform(y_test)  \n",
        "y_train_inversed = scaler.inverse_transform(y_train)\n",
        "y_val_inversed = scaler.inverse_transform(y_val)\n",
        "\n",
        "\n",
        "total_train_rmse = 0\n",
        "total_train_mae = 0\n",
        "total_train_mse = 0\n",
        "\n",
        "total_test_rmse = 0\n",
        "total_test_mae = 0\n",
        "total_test_mse = 0\n",
        "for i in range(test_predict.shape[1]):\n",
        "  train_score = math.sqrt(mean_squared_error(y_train[:, i], train_predict[:,  i]))\n",
        "  train_mse_score = mean_squared_error(y_train[:, i], train_predict[:,  i])\n",
        "  train_mae_score = mean_absolute_error(y_train[:, i], train_predict[:,  i])\n",
        "  print('Train Score: %.5f RMSE' % (train_score))\n",
        "  print('Train Score: %.5f MAE' % (train_mae_score))\n",
        "  print('Train Score: %.5f MSE' % (train_mse_score))\n",
        "  total_train_rmse += train_score\n",
        "  total_train_mae += train_mae_score\n",
        "  total_train_mse += train_mse_score\n",
        "  # # print(len(test_predict))\n",
        "  # # print(len(y_test))\n",
        "  test_score = math.sqrt(mean_squared_error(y_test[:, i], test_predict[:,  i]))\n",
        "  test_mae_score = mean_absolute_error(y_test[:, i], test_predict[:,  i])\n",
        "  test_mse_score = mean_squared_error(y_test[:, i], test_predict[:,  i])\n",
        "  print('Test Score: %.5f RMSE' % (test_score))\n",
        "  print('Test Score: %.5f MAE' % (test_mae_score))\n",
        "  print('Test Score: %.5f MSE' % (test_mse_score))\n",
        "  total_test_rmse += test_score\n",
        "  total_test_mae += test_mae_score\n",
        "  total_test_mse += test_mse_score\n",
        "  fig, ax = plt.subplots()\n",
        "  predicted_values = test_predict_inversed[:, i]\n",
        "  real_values = y_test_inversed[:, i]\n",
        "  # print(predicted_values)\n",
        "  horas = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
        "           20, 21, 22, 23]\n",
        "  ax.plot(horas, real_values[22:46], color = 'red', label = 'Reales')\n",
        "  ax.plot(horas, predicted_values[22:46], color = 'blue', label = 'Predichos')\n",
        "  # ax.plot(real_values, color = 'red', label = 'Reales')\n",
        "  # ax.plot(predicted_values, color = 'blue', label = 'Predichos')\n",
        "  # ax.set_title(train_keys[i])\n",
        "  if len(ordered_data[ordered_data.ATA==train_keys[i]]) > 0:\n",
        "    name = ordered_data[ordered_data.ATA==train_keys[i]].desc.iloc[0]\n",
        "  else:\n",
        "    name = train_keys[i]\n",
        "  # if len(name) > 15:\n",
        "    # name = name[0:20] +\"...\"\n",
        "  ax.set_xlabel('Hora')\n",
        "  ax.set_title(name)\n",
        "  # ax.set_xticks(x)\n",
        "  # ax.set_xticks\n",
        "  # ax.set_xticklabels([v for v in test_hours[4:1800]])\n",
        "  ax.tick_params(labelsize ='medium', pad = 5, direction = 'out', rotation = 45)\n",
        "  ax.set_ylabel('Vehiculos')\n",
        "  ax.set_xticks(np.arange(len(horas)))\n",
        "  ax.legend()\n",
        "  plt.xticks(rotation='vertical')\n",
        "  plt.show()\n",
        "  print(\"ATA -------> \", train_keys[i])\n",
        "  print(\"-------------------- ACABA AQUI, CALLE NUEVA -----------------------\")\n",
        "print('Total train Score: %.4f RMSE' % (total_train_rmse))\n",
        "print('Total train Score: %.4f MAE' % (total_train_mae))\n",
        "print('Total train Score: %.4f MSE' % (total_train_mse))\n",
        "\n",
        "print('Total test Score: %.4f RMSE' % (total_test_rmse))\n",
        "print('Total test Score: %.4f MAE' % (total_test_mae))\n",
        "print('Total test Score: %.4f MSE' % (total_test_mse))\n",
        "\n",
        "\n",
        "print('AVG train Score: %.4f RMSE' % (total_train_rmse / features))\n",
        "print('AVG train Score: %.4f MAE' % (total_train_mae / features))\n",
        "print('AVG train Score: %.4f MSE' % (total_train_mse / features))\n",
        "\n",
        "\n",
        "print('AVG test Score: %.4f RMSE' % (total_test_rmse / features))\n",
        "print('AVG test Score: %.4f MAE' % (total_test_mae / features))\n",
        "print('AVG test Score: %.4f MSE' % (total_test_mse / features))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzj_yCQny0Jm"
      },
      "source": [
        "train_mse_score = mean_squared_error(y_train, train_predict)\n",
        "print(\"TRAIN MSE\", train_mse_score)\n",
        "train_mae_score = mean_absolute_error(y_train, train_predict)\n",
        "print(\"TRAIN MAE\", train_mae_score)\n",
        "train_rmse_score = math.sqrt(mean_squared_error(y_train, train_predict))\n",
        "print(\"TRAIN RMSE\", train_rmse_score)\n",
        "\n",
        "val_mse_score = mean_squared_error(y_val, val_predict)\n",
        "print(\"VAL MSE\", val_mse_score)\n",
        "val_mae_score = mean_absolute_error(y_val, val_predict)\n",
        "print(\"VAL MAE\", val_mae_score)\n",
        "val_rmse_score = math.sqrt(mean_squared_error(y_val, val_predict))\n",
        "print(\"VAL RMSE\", val_rmse_score)\n",
        "\n",
        "test_mse_score = mean_squared_error(y_test, test_predict)\n",
        "print(\"TEST MSE\", test_mse_score)\n",
        "test_mae_score = mean_absolute_error(y_test, test_predict)\n",
        "print(\"TEST MAE\", test_mae_score)\n",
        "test_rmse_score = math.sqrt(mean_squared_error(y_test, test_predict))\n",
        "print(\"TEST RMSE\", test_rmse_score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6co5_CLLYAq"
      },
      "source": [
        "Para el análisis del error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q48LHn4aYny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0906486b-93eb-474e-b52e-3b7049dce9cc"
      },
      "source": [
        "e_tipos = {}\n",
        "e_barrios = {}\n",
        "e_festivos = {}\n",
        "e_calles = {}\n",
        "\n",
        "for i in range(test_predict.shape[1]):\n",
        "  ATA = test_keys[i]\n",
        "  tipo = list(set(ordered_data.loc[ordered_data.ATA==ATA].tipo))\n",
        "  barrio = list(set(ordered_data.loc[ordered_data.ATA==ATA].barrio))\n",
        "  festivo = list(set(ordered_data.loc[ordered_data.ATA==ATA].festivo))\n",
        "  test_score = math.sqrt(mean_squared_error(y_test[:, i], test_predict[:,  i]))\n",
        "  test_mae_score = mean_absolute_error(y_test[:, i], test_predict[:,  i])\n",
        "  test_mse_score = mean_squared_error(y_test[:, i], test_predict[:,  i])\n",
        "  if len(tipo) > 0:\n",
        "    e_calles[ATA] = test_mae_score\n",
        "    tipo = tipo[0]\n",
        "    if tipo == \"resdiencial\":\n",
        "      tipo = \"residencial\"\n",
        "    if tipo in e_tipos.keys():\n",
        "      e_tipos[tipo] += test_mae_score\n",
        "    else:\n",
        "      e_tipos[tipo] = test_mae_score\n",
        "  else:\n",
        "    print(ATA)\n",
        "  if len(barrio) > 0:\n",
        "    barrio = barrio[0]\n",
        "    if barrio in e_barrios.keys():\n",
        "      e_barrios[barrio] += test_mae_score\n",
        "    else:\n",
        "      e_barrios[barrio] = test_mae_score\n",
        "  if len(festivo) > 0:\n",
        "    festivo = festivo[0]\n",
        "    if festivo in e_festivos.keys():\n",
        "      e_festivos[festivo] += test_mae_score\n",
        "    else:\n",
        "      e_festivos[festivo] = test_mae_score\n",
        "    \n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A229\n",
            "A302\n",
            "B46\n",
            "B47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EooX8nyznFyv",
        "outputId": "d586a594-288a-488c-89cb-d605b0bbfb29"
      },
      "source": [
        "e_tipos['terciaria']"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.647378"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxVsjXExgS59"
      },
      "source": [
        "primarias = {}\n",
        "secundarias = {}\n",
        "terciarias = {}\n",
        "entradas = {}\n",
        "salidas = {}\n",
        "residenciales = {}\n",
        "\n",
        "for ATA in e_calles.keys():\n",
        "  tipo = ordered_data[ordered_data.ATA==ATA].iloc[0].tipo\n",
        "  if tipo == \"primaria\":\n",
        "    primarias[ATA] = e_calles[ATA]\n",
        "  elif tipo == \"secundaria\":\n",
        "    secundarias[ATA] = e_calles[ATA]\n",
        "  elif tipo == \"terciaria\":\n",
        "    terciarias[ATA] = e_calles[ATA]\n",
        "  elif tipo == \"entrada\":\n",
        "    entradas[ATA] = e_calles[ATA]\n",
        "  elif tipo == \"salida\":\n",
        "    salidas[ATA] = e_calles[ATA]\n",
        "  else:\n",
        "    residenciales[ATA] = e_calles[ATA]        \n",
        "\n",
        "  "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tb0FCUXnWgC"
      },
      "source": [
        "primarias_ordenadas = sorted(primarias.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n",
        "secundarias_ordenadas = sorted(secundarias.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n",
        "terciarias_ordenadas = sorted(terciarias.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n",
        "entradas_ordenadas = sorted(entradas.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n",
        "salidas_ordenadas = sorted(salidas.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n",
        "residenciales_ordenadas = sorted(residenciales.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCJsD1TEvzp0"
      },
      "source": [
        "print(\"MAE medio calles primarias \", sum(primarias.values()) / len(primarias.values()))\n",
        "print(\"MAE medio calles secundarias \", sum(secundarias.values()) / len(secundarias.values()))\n",
        "print(\"MAE medio calles terciarias \", sum(terciarias.values()) / len(terciarias.values()))\n",
        "print(\"MAE medio entradas \", sum(entradas.values()) / len(entradas.values()))\n",
        "print(\"MAE medio salidas \", sum(salidas.values()) / len(salidas.values()))\n",
        "print(\"MAE medio calles residenciales \", sum(residenciales.values()) / len(residenciales.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnP1o9MLraSS"
      },
      "source": [
        "items = primarias_ordenadas[:10]\n",
        "keys, values = [], []\n",
        "\n",
        "for k, v in items:\n",
        "  # keys.append(k)\n",
        "  name = ordered_data[ordered_data.ATA==k].desc.iloc[0]\n",
        "  if len(name) > 15:\n",
        "    name = name[0:20] +\"...\"\n",
        "  keys.append(name)\n",
        "  values.append(v)\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title(\"10 calles primarias con más MAE\")\n",
        "ax.bar(keys, values)\n",
        "ax.set_xlabel('Calle')\n",
        "ax.set_ylabel('MAE')\n",
        "plt.xticks(rotation=90)\n",
        "mae_prim = 0\n",
        "for v in primarias.values():\n",
        "  mae_prim += v\n",
        "\n",
        "plt.axhline(mae_prim/len(primarias.values()), 0, 1, label='media', color='red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqGmeOcOt-Al"
      },
      "source": [
        "items = secundarias_ordenadas[:10]\n",
        "keys, values = [], []\n",
        "for k, v in items:\n",
        "  # keys.append(k)\n",
        "  name = ordered_data[ordered_data.ATA==k].desc.iloc[0]\n",
        "  if len(name) > 15:\n",
        "    name = name[0:20] +\"...\"\n",
        "  keys.append(name)\n",
        "  values.append(v)\n",
        "mae_secun = 0\n",
        "for v in secundarias.values():\n",
        "  mae_secun += v\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title(\"10 calles secundarias con más MAE\")\n",
        "ax.bar(keys, values)\n",
        "ax.set_xlabel('Calle')\n",
        "ax.set_ylabel('MAE')\n",
        "plt.xticks(rotation = 90)\n",
        "plt.axhline(mae_secun/len(secundarias.values()), 0, 1, label='media', color='red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG0IM2VNuGto"
      },
      "source": [
        "items = terciarias_ordenadas[:10]\n",
        "keys, values = [], []\n",
        "for k, v in items:\n",
        "  # keys.append(k)\n",
        "  name = ordered_data[ordered_data.ATA==k].desc.iloc[0]\n",
        "  if len(name) > 15:\n",
        "    name = name[0:20] +\"...\"\n",
        "  keys.append(name)\n",
        "  values.append(v)\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title(\"10 calles terciarias con más MAE\")\n",
        "ax.bar(keys, values)\n",
        "ax.set_xlabel('Calle')\n",
        "plt.xticks(rotation = 90)\n",
        "ax.set_ylabel('MAE')\n",
        "mae_ter = 0\n",
        "for v in terciarias.values():\n",
        "  mae_ter += v\n",
        "\n",
        "plt.axhline(mae_ter/len(terciarias.values()), 0, 1, label='media', color='red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD3orpuDuk-z"
      },
      "source": [
        "items = entradas_ordenadas[:10]\n",
        "keys, values = [], []\n",
        "for k, v in items:\n",
        "  # keys.append(k)\n",
        "  name = ordered_data[ordered_data.ATA==k].desc.iloc[0]\n",
        "  if len(name) > 15:\n",
        "    name = name[0:20] +\"...\"\n",
        "  keys.append(name)\n",
        "  values.append(v)\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title(\"Entradas con más MAE\")\n",
        "ax.bar(keys, values)\n",
        "ax.set_xlabel('Calle')\n",
        "ax.set_ylabel('MAE')\n",
        "plt.xticks(rotation = 90)\n",
        "mae_ent = 0\n",
        "for v in entradas.values():\n",
        "  mae_ent += v\n",
        "\n",
        "plt.axhline(mae_ent/len(entradas.values()), 0, 1, label='media', color='red')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hARIEqGuwIA"
      },
      "source": [
        "items = salidas_ordenadas[:10]\n",
        "keys, values = [], []\n",
        "for k, v in items:\n",
        "  # keys.append(k)\n",
        "  name = ordered_data[ordered_data.ATA==k].desc.iloc[0]\n",
        "  if len(name) > 15:\n",
        "    name = name[0:30] +\"...\"\n",
        "  keys.append(name)\n",
        "  values.append(v)\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title(\"Salidas con más MAE\")\n",
        "ax.bar(keys, values)\n",
        "ax.set_xlabel('Calle')\n",
        "ax.set_ylabel('MAE')\n",
        "plt.xticks(rotation = 90)\n",
        "mae_sal = 0\n",
        "for v in salidas.values():\n",
        "  mae_sal += v\n",
        "\n",
        "plt.axhline(mae_sal/len(salidas.values()), 0, 1, label='media', color='red')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-UetpVu19Q"
      },
      "source": [
        "items = residenciales_ordenadas[:10]\n",
        "keys, values = [], []\n",
        "for k, v in items:\n",
        "  # keys.append(k)\n",
        "  name = ordered_data[ordered_data.ATA==k].desc.iloc[0]\n",
        "  if len(name) > 15:\n",
        "    name = name[0:20] +\"...\"\n",
        "  keys.append(name)\n",
        "  values.append(v)\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title(\"10 calles residenciales con más MAE\")\n",
        "ax.bar(keys, values)\n",
        "ax.set_xlabel('Calle')\n",
        "ax.set_ylabel('MAE')\n",
        "plt.xticks(rotation = 90)\n",
        "mae_res = 0\n",
        "for v in residenciales.values():\n",
        "  mae_res += v\n",
        "\n",
        "plt.axhline(mae_res/len(residenciales.values()), 0, 1, label='media', color='red')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}