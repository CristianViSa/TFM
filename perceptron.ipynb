{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA_fJ7uL1t4u"
      },
      "source": [
        "Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cmv_LIq09Cw"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import time\n",
        "import keras.backend as K\n",
        "import math\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, LSTM, Bidirectional, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import auc, roc_curve, auc, mean_squared_error, mean_absolute_error\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import concatenate\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCVaCO3Y1xAq"
      },
      "source": [
        "Paths y lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_UgA3opO0D"
      },
      "source": [
        "full_data_path = \"/content/drive/MyDrive/datos_web/otros/test3.csv\"\n",
        "ordered_data_path = \"/content/drive/MyDrive/datos_web/otros/cleaned_ordered.csv\"\n",
        "# ordered_data_path = \"/content/drive/MyDrive/datos_web/otros/cleaned_ordered_2.csv\"\n",
        "final_data_path = \"/content/drive/MyDrive/datos_web/otros/final_data.csv\"\n",
        "\n",
        "# test_cleaned_full_path = \"/content/drive/MyDrive/datos_web/otros/full_cleaned.csv\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWUGIlifC0wX"
      },
      "source": [
        "final_data = pd.read_csv(final_data_path)\n",
        "dates = pd.to_datetime(final_data[\"Unnamed: 0\"].values)\n",
        "final_data.drop(\"Unnamed: 0\", axis = 1, inplace=True)\n",
        "final_data.set_index(dates, inplace=True)\n",
        "\n",
        "ordered_data = pd.read_csv(ordered_data_path)\n",
        "ordered_data.drop(\"Unnamed: 0\", axis = 1, inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JUDPOO3162w"
      },
      "source": [
        "Variables y grupos. Seleccionar datos del conjunto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulntu8N8DAcd"
      },
      "source": [
        "barrios = {}\n",
        "tipos = {}\n",
        "carriles = {}\n",
        "entradas = {\n",
        "    \"serreria\" : [\"A233\", \"A415\", \"A235\"],\n",
        "    \"avcid\" : [\"A143\", \"A170\", \"A71\"],\n",
        "    \"blasco\" : [\"A49\", \"A65\", \"A33\", \"A47\"]\n",
        "}\n",
        "\n",
        "print(entradas)\n",
        "salidas = {\n",
        "    \"serreria\" : [\"A74\", \"A5\", \"A51\"],\n",
        "    \"avcid\" : [\"A72\", \"A245\"],\n",
        "    \"blasco\" : [\"A234\", \"A52\"]\n",
        "}\n",
        "# print(salidas)\n",
        "\n",
        "# Barrios\n",
        "grouped = ordered_data.groupby(ordered_data.barrio)\n",
        "for name, group in grouped:\n",
        "  neighs = list(set(group.ATA))\n",
        "  barrios[name] = neighs\n",
        "# print(barrios)\n",
        "\n",
        "# Tipos de calle\n",
        "grouped = ordered_data.groupby(ordered_data.tipo)\n",
        "for name, group in grouped:\n",
        "  types = list(set(group.ATA))\n",
        "  tipos[name] = types\n",
        "# print(tipos)\n",
        "\n",
        "# Mismos carriles\n",
        "grouped = ordered_data.groupby(ordered_data.carriles)\n",
        "for name, group in grouped:\n",
        "  lanes = list(set(group.ATA))\n",
        "  carriles[name] = lanes\n",
        "# print(carriles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bshFEeA8S7n_"
      },
      "source": [
        "barrio = barrios['algiros']\n",
        "\n",
        "datos = final_data[barrio]\n",
        "datos = datos.iloc[datos.index.dayofweek == 0]\n",
        "train = datos[\"2021-03-01 00:00:00\":\"2021-05-23 00:00:00\"]\n",
        "test = datos[\"2021-05-23 00:00:00\":\"2021-05-30 00:00:00\"]\n",
        "\n",
        "\n",
        "mondays_train = train.iloc[train.index.dayofweek == 0]\n",
        "tuesdays_train = train.iloc[train.index.dayofweek == 1]\n",
        "wednesdays_train = train.iloc[train.index.dayofweek == 2]\n",
        "thursdays_train = train.iloc[train.index.dayofweek == 3]\n",
        "fridays_train = train.iloc[train.index.dayofweek == 4]\n",
        "saturdays_train = train.iloc[train.index.dayofweek == 5]\n",
        "sundays_train = train.iloc[train.index.dayofweek == 6]\n",
        "\n",
        "mondays_test = test.iloc[test.index.dayofweek == 0]\n",
        "tuesdays_test = test.iloc[test.index.dayofweek == 1]\n",
        "wednesdays_test = test.iloc[test.index.dayofweek == 2]\n",
        "thursdays_test = test.iloc[test.index.dayofweek == 3]\n",
        "fridays_test = test.iloc[test.index.dayofweek == 4]\n",
        "saturdays_test = test.iloc[test.index.dayofweek == 5]\n",
        "sundays_test = test.iloc[test.index.dayofweek == 6]\n",
        "\n",
        "features = datos.shape[1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3td6WOZVDZGB"
      },
      "source": [
        "entrada = entradas['serreria']\n",
        "datos = final_data[entrada]\n",
        "datos = datos.iloc[datos.index.dayofweek == 0]\n",
        "train = datos[\"2021-03-01 00:00:00\":\"2021-05-23 00:00:00\"]\n",
        "test = datos[\"2021-05-23 00:00:00\":\"2021-05-30 00:00:00\"]\n",
        "\n",
        "\n",
        "mondays_train = train.iloc[train.index.dayofweek == 0]\n",
        "tuesdays_train = train.iloc[train.index.dayofweek == 1]\n",
        "wednesdays_train = train.iloc[train.index.dayofweek == 2]\n",
        "thursdays_train = train.iloc[train.index.dayofweek == 3]\n",
        "fridays_train = train.iloc[train.index.dayofweek == 4]\n",
        "saturdays_train = train.iloc[train.index.dayofweek == 5]\n",
        "sundays_train = train.iloc[train.index.dayofweek == 6]\n",
        "\n",
        "mondays_test = test.iloc[test.index.dayofweek == 0]\n",
        "tuesdays_test = test.iloc[test.index.dayofweek == 1]\n",
        "wednesdays_test = test.iloc[test.index.dayofweek == 2]\n",
        "thursdays_test = test.iloc[test.index.dayofweek == 3]\n",
        "fridays_test = test.iloc[test.index.dayofweek == 4]\n",
        "saturdays_test = test.iloc[test.index.dayofweek == 5]\n",
        "sundays_test = test.iloc[test.index.dayofweek == 6]\n",
        "\n",
        "features = datos.shape[1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFH3L6zECLn3"
      },
      "source": [
        "cols = [\"A71\"]\n",
        "datos = pd.DataFrame(final_data[cols])\n",
        "datos = final_data\n",
        "df = datos\n",
        "datos = datos[\"2021-03-15 00:00:00\":\"2021-06-20 23:00:00\"]\n",
        "datos.fillna(0, inplace=True)\n",
        "# # datos = datos.iloc[datos.index.dayofweek == 0]\n",
        "\n",
        "# Para ajustar parametros\n",
        "# train = datos[\"2021-03-15 00:00:00\":\"2021-05-16 23:00:00\"]\n",
        "val = datos[\"2021-05-17 00:00:00\":\"2021-06-06 23:00:00\"]\n",
        "\n",
        "# Para entrenar modelo final\n",
        "train = datos[\"2021-03-15 00:00:00\":\"2021-06-06 23:00:00\"]\n",
        "test = datos[\"2021-06-07 00:00:00\":\"2021-06-20 23:00:00\"]\n",
        "# test = datos[\"2021-06-01 00:00:00\":\"2021-06-28 23:00:00\"]\n",
        "print(train.isna().sum())\n",
        "print(test.isna().sum())\n",
        "# print(val.isna().sum())\n",
        "\n",
        "# train = datos[\"2021-05-01 00:00:00\":\"2021-05-31 00:00:00\"]\n",
        "# test = datos[\"2021-06-01 00:00:00\":\"2021-06-30 00:00:00\"]\n",
        "\n",
        "# mondays_train = train.iloc[train.index.dayofweek == 0]\n",
        "# tuesdays_train = train.iloc[train.index.dayofweek == 1]\n",
        "# wednesdays_train = train.iloc[train.index.dayofweek == 2]\n",
        "# thursdays_train = train.iloc[train.index.dayofweek == 3]\n",
        "# fridays_train = train.iloc[train.index.dayofweek == 4]\n",
        "# saturdays_train = train.iloc[train.index.dayofweek == 5]\n",
        "# sundays_train = train.iloc[train.index.dayofweek == 6]\n",
        "\n",
        "# mondays_test = test.iloc[test.index.dayofweek == 0]\n",
        "# tuesdays_test = test.iloc[test.index.dayofweek == 1]\n",
        "# wednesdays_test = test.iloc[test.index.dayofweek == 2]\n",
        "# thursdays_test = test.iloc[test.index.dayofweek == 3]\n",
        "# fridays_test = test.iloc[test.index.dayofweek == 4]\n",
        "# saturdays_test = test.iloc[test.index.dayofweek == 5]\n",
        "# sundays_test = test.iloc[test.index.dayofweek == 6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZK0XSZD4I4S"
      },
      "source": [
        "Crear la serie temporal.\n",
        "\n",
        "2 formas diferentes :\n",
        "  1 - Método create_dataset\n",
        "  2 - Método series_to_supervised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdBAqtg9dPCT"
      },
      "source": [
        "def create_dataset(dataset, look_back=1):\n",
        "  dataX, dataY = [], []\n",
        "  for i in range(len(dataset) - look_back):\n",
        "    a = dataset[i: (i + look_back), 0]\n",
        "    dataX.append(a)\n",
        "    dataY.append(dataset[i + look_back, 0])\n",
        "  print(len(dataY))\n",
        "  return np.array(dataX), np.array(dataY)\n",
        "  \n",
        "# timesteps = 1\n",
        "# features = datos.shape[1]\n",
        "# x_train, y_train = create_dataset(train, timesteps)\n",
        "# x_val, y_val = create_dataset(val, timesteps)\n",
        "# x_test, y_test = create_dataset(test, timesteps)\n",
        "\n",
        "\n",
        "# x_train = np.asarray(x_train).astype('float32')\n",
        "# x_train = np.reshape(x_train, (x_train.shape[0], timesteps, features))\n",
        "# y_train = np.asarray(y_train).astype('float32')\n",
        "\n",
        "# x_test = np.asarray(x_test).astype('float32')\n",
        "# x_test = np.reshape(x_test, (x_test.shape[0], timesteps, features))\n",
        "# y_test = np.asarray(y_test).astype('float32')\n",
        "\n",
        "# x_val = np.asarray(x_val).astype('float32')\n",
        "# x_val = np.reshape(x_val, (x_val.shape[0], timesteps, features))\n",
        "# y_val = np.asarray(y_val).astype('float32')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJyTWIGzSyrF"
      },
      "source": [
        "# # Convertir la serie temporal en datos supervisados\n",
        "# Serie sin tener en cuenta informacion adicional, solo la hora anterior\n",
        "def series_to_supervised(data, keys, n_in=1, n_out=1, dropnan=True):\n",
        "  n_vars = 1 if type(data) is list else data.shape[1]\n",
        "  df = pd.DataFrame(data)\n",
        "  cols, names = list(), list()\n",
        "  # input sequence (t-n, ... t-1)\n",
        "  for i in range(n_in, 0, -1):\n",
        "    cols.append(df.shift(i))\n",
        "    names += [('%s(t-%d)' % (keys[j], i)) for j in range(n_vars)]\n",
        "  # forecast sequence (t, t+1, ... t+n)\n",
        "  for i in range(0, n_out):\n",
        "    cols.append(df.shift(-i))\n",
        "    if i == 0:\n",
        "      names += [('%s(t)' % (keys[j])) for j in range(n_vars)]\n",
        "    else:\n",
        "      names += [('%s(t+%d)' % (keys[j], i)) for j in range(n_vars)]\n",
        "  # put it all together\n",
        "  agg = pd.concat(cols, axis=1)\n",
        "  agg.columns = names\n",
        "  # drop rows with NaN values\n",
        "  if dropnan:\n",
        "    agg.dropna(0, inplace=True)\n",
        "  return agg\n",
        "\n",
        "\n",
        "features = train.shape[1]\n",
        "timesteps = 2\n",
        "outputs = 1\n",
        "\n",
        "train_keys = train.keys()\n",
        "test_keys = test.keys()\n",
        "val_keys = val.keys()\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaler = scaler.fit(train)\n",
        "train_values = scaler.transform(train)\n",
        "test_values = scaler.transform(test)\n",
        "val_values = scaler.transform(val)\n",
        "\n",
        "serie_train = series_to_supervised(train_values, train_keys, n_in=timesteps-1, n_out=2)\n",
        "serie_test = series_to_supervised(test_values, test_keys,  n_in=timesteps-1, n_out=2)\n",
        "serie_val = series_to_supervised(val_values, val_keys, n_in=timesteps-1, n_out=2)\n",
        "\n",
        "\n",
        "x_train, y_train = serie_train.values[:, :-features], serie_train.values[:, -features:]\n",
        "x_test, y_test = serie_test.values[:, :-features], serie_test.values[:, -features:]\n",
        "x_val, y_val = serie_val.values[:, :-features], serie_val.values[:, -features:]\n",
        "\n",
        "##############  Resize de los arrays ##########\n",
        "x_train = np.asarray(x_train).astype('float32')\n",
        "x_test = np.asarray(x_test).astype('float32')\n",
        "x_val = np.asarray(x_val).astype('float32')\n",
        "\n",
        "y_train = np.asarray(y_train).astype('float32')\n",
        "y_test = np.asarray(y_test).astype('float32')\n",
        "y_val = np.asarray(y_val).astype('float32')\n",
        "\n",
        "\n",
        "n_input = timesteps * features\n",
        "x_train = x_train.reshape((x_train.shape[0], n_input))\n",
        "x_test = x_test.reshape((x_test.shape[0], n_input))\n",
        "x_val = x_val.reshape((x_val.shape[0], n_input))\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD1YcWlVqqek"
      },
      "source": [
        "####### Crear y entrenar el modelo  ##########\n",
        "batch_size = 24\n",
        "epochs = 200\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim=n_input, activation='relu', name=\"Input\"))\n",
        "model.add(Dense(40, activation='relu', name=\"Hidden\"))\n",
        "model.add(Dense(features, activation='linear', name=\"Output\"))\n",
        "\n",
        "model.summary()\n",
        "metrics=[\"mse\", \"mae\"]\n",
        "model.compile(metrics=metrics, loss='mae', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nop-Fz3ZXs2D"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UPK6Jj4ZjTY"
      },
      "source": [
        "filepath=\"weights.best.hdf5\"\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint, es]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqcLaPLkZkQ2"
      },
      "source": [
        "# Para ajustar\n",
        "history = model.fit(\n",
        "    x_train, y_train, \n",
        "    epochs=epochs, \n",
        "    batch_size=batch_size, \n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=callbacks_list,\n",
        "    shuffle=False,\n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JO38qR47PI5"
      },
      "source": [
        "# Modelo final\n",
        "history = model.fit(\n",
        "    x_train, y_train, \n",
        "    epochs=epochs, \n",
        "    batch_size=batch_size, \n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=callbacks_list,\n",
        "    shuffle=False,\n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Amyt7OZlsv"
      },
      "source": [
        "plt.title(\"MAE\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.plot(history.history['mae'], label='entrenamiento')\n",
        "plt.plot(history.history['val_mae'], label='validacion')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.title(\"MSE\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.plot(history.history['mse'], label='entrenamiento')\n",
        "plt.plot(history.history['val_mse'], label='validacion')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amzSKklU13LK"
      },
      "source": [
        "val_rmse_values = []\n",
        "train_rmse_values = []\n",
        "for i in history.history['val_mse']:\n",
        "  val_rmse_values.append(math.sqrt(i))\n",
        "for i in history.history['mse']:\n",
        "  train_rmse_values.append(math.sqrt(i))\n",
        "\n",
        "\n",
        "plt.title(\"RMSE\")\n",
        "plt.plot(train_rmse_values, label='entrenamiento')\n",
        "plt.plot(val_rmse_values, label='validacion')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvjXEkO5Z_8z"
      },
      "source": [
        "model.load_weights(\"/content/weights.best.hdf5\")\n",
        "# y_test = y_train\n",
        "# # make predictions\n",
        "train_predict = model.predict(x_train)\n",
        "test_predict = model.predict(x_test)\n",
        "val_predict = model.predict(x_val)\n",
        "train_predict_inversed = scaler.inverse_transform(train_predict)\n",
        "test_predict_inversed = scaler.inverse_transform(test_predict)  \n",
        "val_predict_inversed = scaler.inverse_transform(val_predict)  \n",
        "y_test_inversed = scaler.inverse_transform(y_test)  \n",
        "y_train_inversed = scaler.inverse_transform(y_train)\n",
        "y_val_inversed = scaler.inverse_transform(y_val)\n",
        "\n",
        "total_train_rmse = 0\n",
        "total_train_mae = 0\n",
        "total_train_mse = 0\n",
        "\n",
        "total_test_rmse = 0\n",
        "total_test_mae = 0\n",
        "total_test_mse = 0\n",
        "for i in range(test_predict.shape[1]):\n",
        "  train_score = math.sqrt(mean_squared_error(y_train[:, i], train_predict[:,  i]))\n",
        "  train_mse_score = mean_squared_error(y_train[:, i], train_predict[:,  i])\n",
        "  train_mae_score = mean_absolute_error(y_train[:, i], train_predict[:,  i])\n",
        "  print('Train Score: %.2f RMSE' % (train_score))\n",
        "  print('Train Score: %.2f MAE' % (train_mae_score))\n",
        "  print('Train Score: %.2f MSE' % (train_mse_score))\n",
        "  total_train_rmse += train_score\n",
        "  total_train_mae += train_mae_score\n",
        "  total_train_mse += train_mse_score\n",
        "  # # print(len(test_predict))\n",
        "  # # print(len(y_test))\n",
        "  test_score = math.sqrt(mean_squared_error(y_test[:, i], test_predict[:,  i]))\n",
        "  test_mae_score = mean_absolute_error(y_test[:, i], test_predict[:,  i])\n",
        "  test_mse_score = mean_squared_error(y_test[:, i], test_predict[:,  i])\n",
        "  print('Test Score: %.2f RMSE' % (test_score))\n",
        "  print('Test Score: %.2f MAE' % (test_mae_score))\n",
        "  print('Test Score: %.2f MSE' % (test_mse_score))\n",
        "  total_test_rmse += test_score\n",
        "  total_test_mae += test_mae_score\n",
        "  total_test_mse += test_mse_score\n",
        "  fig, ax = plt.subplots()\n",
        "  predicted_values = test_predict_inversed[:, i]\n",
        "  real_values = y_test_inversed[:, i]\n",
        "    # print(predicted_values)\n",
        "  horas = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
        "           20, 21, 22, 23]\n",
        "  ax.plot(horas, real_values[22:46], color = 'red', label = 'Reales')\n",
        "  ax.plot(horas, predicted_values[22:46], color = 'blue', label = 'Predichos')\n",
        "  # ax.set_title(train_keys[i])\n",
        "  if len(ordered_data[ordered_data.ATA==train_keys[i]]) > 0:\n",
        "    name = ordered_data[ordered_data.ATA==train_keys[i]].desc.iloc[0]\n",
        "  else:\n",
        "    name = train_keys[i]\n",
        "  # if len(name) > 15:\n",
        "    # name = name[0:20] +\"...\"\n",
        "  ax.set_xlabel('Hora')\n",
        "  ax.set_title(name)\n",
        "  # ax.set_xticks(x)\n",
        "  # ax.set_xticks\n",
        "  # ax.set_xticklabels([v for v in test_hours[4:1800]])\n",
        "  ax.tick_params(labelsize ='medium', pad = 5, direction = 'out', rotation = 45)\n",
        "  ax.set_ylabel('Vehiculos')\n",
        "  ax.set_xticks(np.arange(len(horas)))\n",
        "  ax.legend()\n",
        "  plt.xticks(rotation='vertical')\n",
        "  plt.show()\n",
        "  print(\"ATA -------> \", train_keys[i])\n",
        "print('Total train Score: %.2f RMSE' % (total_train_rmse))\n",
        "print('Total train Score: %.2f MAE' % (total_train_mae))\n",
        "print('Total train Score: %.2f MSE' % (total_train_mse))\n",
        "\n",
        "print('Total test Score: %.2f RMSE' % (total_test_rmse))\n",
        "print('Total test Score: %.2f MAE' % (total_test_mae))\n",
        "print('Total test Score: %.2f MSE' % (total_test_mse))\n",
        "\n",
        "\n",
        "print('AVG train Score: %.2f RMSE' % (total_train_rmse / features))\n",
        "print('AVG train Score: %.2f MAE' % (total_train_mae / features))\n",
        "print('AVG train Score: %.2f MSE' % (total_train_mse / features))\n",
        "\n",
        "\n",
        "print('AVG test Score: %.2f RMSE' % (total_test_rmse / features))\n",
        "print('AVG test Score: %.2f MAE' % (total_test_mae / features))\n",
        "print('AVG test Score: %.2f MSE' % (total_test_mse / features))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzj_yCQny0Jm"
      },
      "source": [
        "train_mse_score = mean_squared_error(y_train, train_predict)\n",
        "print(\"TRAIN MSE\", train_mse_score)\n",
        "train_mae_score = mean_absolute_error(y_train, train_predict)\n",
        "print(\"TRAIN MAE\", train_mae_score)\n",
        "train_rmse_score = math.sqrt(mean_squared_error(y_train, train_predict))\n",
        "print(\"TRAIN RMSE\", train_rmse_score)\n",
        "\n",
        "val_mse_score = mean_squared_error(y_val, val_predict)\n",
        "print(\"VAL MSE\", val_mse_score)\n",
        "val_mae_score = mean_absolute_error(y_val, val_predict)\n",
        "print(\"VAL MAE\", val_mae_score)\n",
        "val_rmse_score = math.sqrt(mean_squared_error(y_val, val_predict))\n",
        "print(\"VAL RMSE\", val_rmse_score)\n",
        "\n",
        "train_mse_score = mean_squared_error(y_test, test_predict)\n",
        "print(\"TEST MSE\", test_mse_score)\n",
        "train_mae_score = mean_absolute_error(y_test, test_predict)\n",
        "print(\"TEST MAE\", test_mae_score)\n",
        "test_rmse_score = math.sqrt(mean_squared_error(y_test, test_predict))\n",
        "print(\"TEST RMSE\", test_rmse_score)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}